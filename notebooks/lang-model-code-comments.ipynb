{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "from fastai.text import *\n",
    "BOS = '_xbos_ ' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read In Files From Ho-Hsiang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "PATH = Path('/ds/hohsiangwu/projects/semantic_search/')\n",
    "\n",
    "with open(PATH/'train.docstring', 'r') as f:\n",
    "    t_comment = f.readlines()\n",
    "\n",
    "with open(PATH/'valid.docstring', 'r') as f:\n",
    "    v_comment = f.readlines()\n",
    "\n",
    "with open(PATH/'test.docstring', 'r') as f:\n",
    "    holdout_comment = f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Files For Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_flatten(l):\n",
    "    \"List[List] --> List\"\n",
    "    return [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Append begininng of sentence tag \n",
    "- concatenate all text together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "tok_trn = list_flatten([(BOS + x).split() for x in t_comment])\n",
    "tok_val = list_flatten([(BOS + x).split() for x in v_comment])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Vocabulary Dict:\n",
    "- index to string\n",
    "- string to index\n",
    "- use default dict so unknowns are mapped to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-12df99301cd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# index to string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok_trn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# on training set, then applied to val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mitos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_vocab\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mmin_freq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mitos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_pad_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/collections/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    533\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'expected at most 1 arguments, got %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__missing__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/collections/__init__.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    620\u001b[0m                     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# fast path when counter is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m                 \u001b[0m_count_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_vocab = 30000\n",
    "min_freq = 25\n",
    "\n",
    "# index to string\n",
    "freq = Counter(tok_trn) # on training set, then applied to val\n",
    "itos = [o for o,c in freq.most_common(max_vocab) if c>min_freq]\n",
    "itos.insert(0, '_pad_')\n",
    "itos.insert(0, '_unk_')\n",
    "\n",
    "# string to index\n",
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "len(itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Index2String Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save itos\n",
    "import pickle\n",
    "with open('itos_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(itos, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize List of Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67358009, 2832093)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_lm = np.array([stoi[s] for s in tok_trn])\n",
    "val_lm = np.array([stoi[s] for s in tok_val])\n",
    "len(trn_lm), len(val_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = Path('/ds/hamel/CodeML/Get_Python_From_BigQuery/')\n",
    "# np.save(PATH/'trn_lm.npy', trn_lm)\n",
    "# np.save(PATH/'val_lm.npy', val_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Language Model Using Fastai  (You Can Run From Here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 16K\r\n",
      "drwxr-xr-x 4 root root 6.0K Apr 24 00:13 .\r\n",
      "drwxr-xr-x 9 1001 1001 6.0K May  3 02:30 ..\r\n",
      "drwxr-xr-x 2 root root 6.0K Apr 30 23:21 models\r\n",
      "drwxr-xr-x 2 root root 6.0K Apr 24 00:13 tmp\r\n"
     ]
    }
   ],
   "source": [
    "! ls -lah code_comment_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "\n",
    "PATH = Path('/ds/hamel/CodeML/Get_Python_From_BigQuery/')\n",
    "from fastai.text import *\n",
    "\n",
    "trn_lm = np.load(PATH/'trn_lm.npy')\n",
    "val_lm = np.load(PATH/'val_lm.npy')\n",
    "\n",
    "with open(PATH/'lm_itos_dict.pkl', 'rb') as f:\n",
    "    itos = pickle.load(f)\n",
    "\n",
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_xbos_',\n",
       " 'render',\n",
       " 'this',\n",
       " 'object',\n",
       " 'as',\n",
       " 'a',\n",
       " 'dict',\n",
       " 'of',\n",
       " 'its',\n",
       " 'fields']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[itos[x] for x in trn_lm[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models\ttmp\r\n"
     ]
    }
   ],
   "source": [
    "!ls /ds/hamel/fastai/courses/dl1/code_comment_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=Path('/ds/hamel/fastai/courses/dl1/code_comment_lm')\n",
    "#PATH.mkdir(exist_ok=True)\n",
    "\n",
    "em_sz,nh,nl = 400,400,3\n",
    "wd=1e-7\n",
    "bptt=20\n",
    "bs=32\n",
    "vs=len(itos)\n",
    "\n",
    "\n",
    "with torch.cuda.device(3):\n",
    "    torch.cuda.empty_cache()\n",
    "    trn_dl = LanguageModelLoader(trn_lm, bs, bptt)\n",
    "    val_dl = LanguageModelLoader(val_lm, bs, bptt)\n",
    "    md = LanguageModelData(PATH, 1, vs, trn_dl, val_dl, bs=bs, bptt=bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.device(3):\n",
    "    torch.cuda.empty_cache()\n",
    "    opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n",
    "    drops = np.array([0.25, 0.1, 0.2, 0.02, 0.15])*0.7\n",
    "    learner= md.get_model(opt_fn, em_sz, nh, nl, \n",
    "                            dropouti=drops[0], \n",
    "                            dropout=drops[1], \n",
    "                            wdrop=drops[2], \n",
    "                            dropoute=drops[3], \n",
    "                            dropouth=drops[4])\n",
    "    lr=1e-3\n",
    "    lrs = lr\n",
    "    #learner.lr_find(start_lr=lrs/10, end_lr=lrs*10, linear=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3 / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'code_comment_lm_v3.fai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4823b430bd4dc1807f4b71255558b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1%|          | 644/105245 [00:20<55:05, 31.64it/s, loss=6.32]  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-657d40fb96e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_clr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/hamel/fastai/courses/dl1/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, lrs, n_cycle, wds, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwarm_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hamel/fastai/courses/dl1/fastai/learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[0;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, best_save_name, use_clr, use_clr_beta, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, use_swa, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mswa_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_model\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_swa\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswa_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswa_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             swa_eval_freq=swa_eval_freq, **kwargs)\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hamel/fastai/courses/dl1/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_stepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hamel/fastai/courses/dl1/fastai/model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xs, y, epoch)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mcopy_fp32_to_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp32_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hamel/fastai/courses/dl1/fastai/model.py\u001b[0m in \u001b[0;36mtorch_item\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mtorch_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mStepper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(3):\n",
    "    learner.fit(lrs, 1, wds=wd, cycle_len=3, use_clr=(32,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.sched.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.save('code_comment_lm_v3.fai')\n",
    "# learner.save_encoder('code_comment_lm_encoder_v3.fai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 644/105245 [00:40<1:48:17, 16.10it/s, loss=6.32]"
     ]
    }
   ],
   "source": [
    "learner.load('code_comment_lm_v3.fai')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize All Comments (Create Universal Sent Encoder For Comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import collections\n",
    "\n",
    "with open('itos_dict.pkl', 'rb') as f:\n",
    "    itos = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "PATH = Path('/ds/hohsiangwu/projects/semantic_search/')\n",
    "\n",
    "with open(PATH/'train.docstring', 'r') as f:\n",
    "    t_comment = f.readlines()\n",
    "\n",
    "with open(PATH/'valid.docstring', 'r') as f:\n",
    "    v_comment = f.readlines()\n",
    "\n",
    "with open(PATH/'test.docstring', 'r') as f:\n",
    "    holdout_comment = f.readlines()\n",
    "\n",
    "\n",
    "# The reason you are rebuilding this is that the data fed into the language model was completely flattened and\n",
    "#  concatenated, whereas here you want to maintain the list of \n",
    "tok_trn_list = [(BOS + x).split() for x in t_comment]\n",
    "tok_val_list = [(BOS + x).split() for x in v_comment]\n",
    "tok_hld_list = [(BOS + x).split() for x in holdout_comment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_trn_list = [[stoi[a] for a in x] for x in tok_trn_list]\n",
    "idx_val_list = [[stoi[a] for a in x] for x in tok_val_list]\n",
    "idx_hld_list = [[stoi[a] for a in x] for x in tok_hld_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def list2arr(l):\n",
    "    \"Convert list into pytorch Variable.\"\n",
    "    return V(np.expand_dims(np.array(l), -1)).cpu()\n",
    "\n",
    "def make_prediction_from_list(model, l):\n",
    "    \"\"\"\n",
    "    Encode a list of integers that represent a sequence of tokens.  The\n",
    "    purpose is to encode a sentence or phrase.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    model : fastai language model\n",
    "    l : list\n",
    "        list of integers, representing a sequence of tokens that you want to encode\n",
    "        \n",
    "    \"\"\"\n",
    "    #with torch.cuda.device(3):\n",
    "    arr = list2arr(l)# turn list into pytorch Variable with bs=1\n",
    "    model.reset()  # language model is stateful, so you must reset upon each prediction\n",
    "    hidden_states = model(arr)[-1][-1] # RNN Hidden Layer output is last output, and only need the last layer\n",
    "    \n",
    "    #return avg-pooling, max-pooling, and last hidden state\n",
    "    return hidden_states.mean(0), hidden_states.max(0)[0], hidden_states[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(lm_model, list_list_int):\n",
    "    \"\"\"\n",
    "    Vectorize a list of sequences List[List[int]] using a fast.ai language model. \n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    lm_model : fastai language model\n",
    "    list_list_int : List[List[int]]\n",
    "        A list of sequences to encode\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    tuple: (avg, mean, last)\n",
    "        A tuple that returns the average-pooling, max-pooling over time steps as well as the last time step.\n",
    "    \"\"\"\n",
    "    avg_embs, mean_embs, last_embs = [], [], []\n",
    "\n",
    "    for i in tqdm_notebook(range(len(list_list_int))):\n",
    "        avg_, max_, last_ = make_prediction_from_list(lm_model, list_list_int[i])\n",
    "        avg_embs.append(avg_)\n",
    "        mean_embs.append(max_)\n",
    "        last_embs.append(last_)\n",
    "    \n",
    "    return torch.cat(avg_embs), torch.cat(mean_embs), torch.cat(last_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): RNN_Encoder(\n",
       "    (encoder): Embedding(33243, 400, padding_idx=1)\n",
       "    (encoder_with_dropout): EmbeddingDropout(\n",
       "      (embed): Embedding(33243, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDrop(\n",
       "        (module): LSTM(400, 400, dropout=0.105)\n",
       "      )\n",
       "      (1): WeightDrop(\n",
       "        (module): LSTM(400, 400, dropout=0.105)\n",
       "      )\n",
       "      (2): WeightDrop(\n",
       "        (module): LSTM(400, 400, dropout=0.105)\n",
       "      )\n",
       "    )\n",
       "    (dropouti): LockedDropout(\n",
       "    )\n",
       "    (dropouths): ModuleList(\n",
       "      (0): LockedDropout(\n",
       "      )\n",
       "      (1): LockedDropout(\n",
       "      )\n",
       "      (2): LockedDropout(\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=33243, bias=False)\n",
       "    (dropout): LockedDropout(\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.load('code_comment_lm_v3.fai')\n",
    "learner.model.eval() # make sure dropout and bn are not activated during prediction\n",
    "learner.model.cpu()\n",
    "#train_avg_emb, train_mean_emb, train_last_emb = get_embeddings(learner.model.cpu(), idx_trn_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATH = Path('/ds/hamel/CodeML/Get_Python_From_BigQuery/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(train_avg_emb, PATH/'train_avg_emb.torchtensor')\n",
    "# torch.save(train_mean_emb, PATH/'train_max_emb.torchtensor') #supposed to be max, not mean!\n",
    "# torch.save(train_last_emb, PATH/'train_last_emb.torchtensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(PATH/'train_avg_emb.npy', train_avg_emb.data.numpy())\n",
    "# np.save(PATH/'train_max_emb.npy', train_mean_emb.data.numpy())\n",
    "# np.save(PATH/'train_last_emb.npy', train_last_emb.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ba797cd3bb5458cb515aeb21e7dba7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=201155), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# val_avg_emb, val_max_emb, val_last_emb = get_embeddings(learner.model.cpu(), idx_val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(val_avg_emb, PATH/'val_avg_emb.torchtensor')\n",
    "# torch.save(val_max_emb, PATH/'val_max_emb.torchtensor') #supposed to be max, not mean!\n",
    "# torch.save(val_last_emb, PATH/'val_last_emb.torchtensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(PATH/'val_avg_emb.npy', val_avg_emb.data.numpy())\n",
    "# np.save(PATH/'val_max_emb.npy', val_max_emb.data.numpy())\n",
    "# np.save(PATH/'val_last_emb.npy', val_last_emb.data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concatenation, etc of these vectors are continued in the CPU notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Lang Model Artificacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# PATH = Path('/ds/hamel/CodeML/Get_Python_From_BigQuery/')\n",
    "\n",
    "# with open(PATH/'lm_itos_dict.pkl', 'wb') as f:\n",
    "#     pickle.dump(itos, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_fastai_codecomment_model = learner.model.cpu()\n",
    "\n",
    "PATH = Path('/ds/hamel/CodeML/Get_Python_From_BigQuery/')\n",
    "torch.save(lm_fastai_codecomment_model, PATH/'lm_fastai_codecomment_model.pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "\n",
    "\n",
    "#notice all the stuff you have to do to make sure its on cpu\n",
    "\n",
    "# x_arr = np.expand_dims(np.array(idx_val_list[0]), -1)\n",
    "# test_model.eval()\n",
    "# results = test_model(V(T(x_arr)).cpu())\n",
    "# test_model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_fastai_codecomment_model = learner.model.cpu()\n",
    "PATH = Path('/ds/hamel/CodeML/Get_Python_From_BigQuery/')\n",
    "torch.save(lm_fastai_codecomment_model.state_dict(), PATH/'lm_fastai_codecomment_model_state_dict.pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = torch.load(PATH/'lm_fastai_codecomment_model_state_dict.pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.model.load_state_dict(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.model.eval() # make sure dropout and bn are not activated during prediction\n",
    "test_model = learner.model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): RNN_Encoder(\n",
       "    (encoder): Embedding(33243, 400, padding_idx=1)\n",
       "    (encoder_with_dropout): EmbeddingDropout(\n",
       "      (embed): Embedding(33243, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDrop(\n",
       "        (module): LSTM(400, 400, dropout=0.105)\n",
       "      )\n",
       "      (1): WeightDrop(\n",
       "        (module): LSTM(400, 400, dropout=0.105)\n",
       "      )\n",
       "      (2): WeightDrop(\n",
       "        (module): LSTM(400, 400, dropout=0.105)\n",
       "      )\n",
       "    )\n",
       "    (dropouti): LockedDropout(\n",
       "    )\n",
       "    (dropouths): ModuleList(\n",
       "      (0): LockedDropout(\n",
       "      )\n",
       "      (1): LockedDropout(\n",
       "      )\n",
       "      (2): LockedDropout(\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=33243, bias=False)\n",
       "    (dropout): LockedDropout(\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " -1.9948e-01 -6.0683e+00 -1.6551e+00  ...  -6.0885e+00 -6.0862e+00 -6.0683e+00\n",
       "  1.9821e+00 -5.8145e+00  7.9009e-01  ...  -5.8813e+00 -5.8475e+00 -5.8146e+00\n",
       "  3.8231e-01 -8.7099e+00 -1.1992e+00  ...  -8.7257e+00 -8.7168e+00 -8.7099e+00\n",
       "                 ...                   â‹±                   ...                \n",
       "  6.6529e-01 -9.1462e+00 -1.7246e+00  ...  -9.1607e+00 -9.1521e+00 -9.1462e+00\n",
       " -1.5618e-01 -9.9707e+00 -4.2412e+00  ...  -9.9758e+00 -9.9622e+00 -9.9707e+00\n",
       "  3.1648e+00 -7.1095e+00  9.1025e+00  ...  -7.1357e+00 -7.1131e+00 -7.1095e+00\n",
       " [torch.FloatTensor of size 10x33243], [Variable containing:\n",
       "  ( 0 ,.,.) = \n",
       "   -3.3752e-02 -5.8660e-01  3.0104e-03  ...  -4.3180e-03  1.9405e-04 -5.8076e-04\n",
       "  \n",
       "  ( 1 ,.,.) = \n",
       "    6.9109e-02 -7.8205e-03 -1.5085e-01  ...  -6.8334e-03 -8.9473e-04  6.3504e-02\n",
       "  \n",
       "  ( 2 ,.,.) = \n",
       "    8.2495e-05  6.2996e-02 -8.6196e-02  ...   5.4503e-03  1.2820e-02  7.6637e-06\n",
       "  ... \n",
       "  \n",
       "  ( 7 ,.,.) = \n",
       "    1.8740e-04 -2.6275e-02 -1.9584e-02  ...   9.4858e-03 -4.1296e-01  2.0350e-02\n",
       "  \n",
       "  ( 8 ,.,.) = \n",
       "    9.7006e-04  5.4827e-01 -2.0219e-02  ...   4.6218e-03 -3.1774e-02  8.4720e-02\n",
       "  \n",
       "  ( 9 ,.,.) = \n",
       "    1.9952e-01  1.2865e-02 -5.7523e-03  ...   3.3903e-04 -4.7655e-04 -5.2961e-03\n",
       "  [torch.FloatTensor of size 10x1x400], Variable containing:\n",
       "  ( 0 ,.,.) = \n",
       "    1.1044e-02  1.9170e-01  2.2044e-03  ...   2.4857e-03  6.7897e-02 -9.4716e-03\n",
       "  \n",
       "  ( 1 ,.,.) = \n",
       "   -3.7100e-01  1.7624e-03  4.1646e-02  ...  -1.9213e-01  3.0189e-03 -1.4618e-01\n",
       "  \n",
       "  ( 2 ,.,.) = \n",
       "   -1.9678e-02  5.8238e-02 -2.9056e-03  ...  -9.8343e-03 -5.3188e-05 -4.9627e-02\n",
       "  ... \n",
       "  \n",
       "  ( 7 ,.,.) = \n",
       "    6.9005e-04  1.6729e-03 -1.3977e-01  ...   5.3245e-03 -1.0771e-03 -1.7479e-02\n",
       "  \n",
       "  ( 8 ,.,.) = \n",
       "    1.9658e-05  1.5645e-01 -9.0592e-03  ...   1.2536e-01 -2.6326e-04 -7.7989e-03\n",
       "  \n",
       "  ( 9 ,.,.) = \n",
       "    4.5020e-04  1.8184e-02 -2.3321e-01  ...  -1.9642e-01 -1.3272e-02 -1.3858e-01\n",
       "  [torch.FloatTensor of size 10x1x400], Variable containing:\n",
       "  ( 0 ,.,.) = \n",
       "   -8.3784e-02 -1.2366e-01 -4.5763e-03  ...   1.4088e-01  2.3160e-02  1.6579e-02\n",
       "  \n",
       "  ( 1 ,.,.) = \n",
       "    1.0026e-02  2.5861e-04 -3.5999e-03  ...   1.6859e-02  5.2949e-03  3.5296e-02\n",
       "  \n",
       "  ( 2 ,.,.) = \n",
       "    1.7713e-01 -1.7961e-01  1.0430e-01  ...   4.8649e-04 -2.1132e-01 -1.4650e-02\n",
       "  ... \n",
       "  \n",
       "  ( 7 ,.,.) = \n",
       "    1.0125e-01  7.5279e-02 -4.1263e-03  ...  -1.3016e-03 -1.9892e-02  3.0247e-02\n",
       "  \n",
       "  ( 8 ,.,.) = \n",
       "    5.5009e-02 -4.5345e-01 -5.2930e-03  ...   3.5153e-03 -3.5104e-02  6.1875e-03\n",
       "  \n",
       "  ( 9 ,.,.) = \n",
       "    4.6364e-03  7.6946e-03 -1.1887e-02  ...   2.8283e-01  1.0168e-02  1.5855e-02\n",
       "  [torch.FloatTensor of size 10x1x400]], [Variable containing:\n",
       "  ( 0 ,.,.) = \n",
       "   -3.3752e-02 -5.8660e-01  3.0104e-03  ...  -4.3180e-03  1.9405e-04 -5.8076e-04\n",
       "  \n",
       "  ( 1 ,.,.) = \n",
       "    6.9109e-02 -7.8205e-03 -1.5085e-01  ...  -6.8334e-03 -8.9473e-04  6.3504e-02\n",
       "  \n",
       "  ( 2 ,.,.) = \n",
       "    8.2495e-05  6.2996e-02 -8.6196e-02  ...   5.4503e-03  1.2820e-02  7.6637e-06\n",
       "  ... \n",
       "  \n",
       "  ( 7 ,.,.) = \n",
       "    1.8740e-04 -2.6275e-02 -1.9584e-02  ...   9.4858e-03 -4.1296e-01  2.0350e-02\n",
       "  \n",
       "  ( 8 ,.,.) = \n",
       "    9.7006e-04  5.4827e-01 -2.0219e-02  ...   4.6218e-03 -3.1774e-02  8.4720e-02\n",
       "  \n",
       "  ( 9 ,.,.) = \n",
       "    1.9952e-01  1.2865e-02 -5.7523e-03  ...   3.3903e-04 -4.7655e-04 -5.2961e-03\n",
       "  [torch.FloatTensor of size 10x1x400], Variable containing:\n",
       "  ( 0 ,.,.) = \n",
       "    1.1044e-02  1.9170e-01  2.2044e-03  ...   2.4857e-03  6.7897e-02 -9.4716e-03\n",
       "  \n",
       "  ( 1 ,.,.) = \n",
       "   -3.7100e-01  1.7624e-03  4.1646e-02  ...  -1.9213e-01  3.0189e-03 -1.4618e-01\n",
       "  \n",
       "  ( 2 ,.,.) = \n",
       "   -1.9678e-02  5.8238e-02 -2.9056e-03  ...  -9.8343e-03 -5.3188e-05 -4.9627e-02\n",
       "  ... \n",
       "  \n",
       "  ( 7 ,.,.) = \n",
       "    6.9005e-04  1.6729e-03 -1.3977e-01  ...   5.3245e-03 -1.0771e-03 -1.7479e-02\n",
       "  \n",
       "  ( 8 ,.,.) = \n",
       "    1.9658e-05  1.5645e-01 -9.0592e-03  ...   1.2536e-01 -2.6326e-04 -7.7989e-03\n",
       "  \n",
       "  ( 9 ,.,.) = \n",
       "    4.5020e-04  1.8184e-02 -2.3321e-01  ...  -1.9642e-01 -1.3272e-02 -1.3858e-01\n",
       "  [torch.FloatTensor of size 10x1x400], Variable containing:\n",
       "  ( 0 ,.,.) = \n",
       "   -8.3784e-02 -1.2366e-01 -4.5763e-03  ...   1.4088e-01  2.3160e-02  1.6579e-02\n",
       "  \n",
       "  ( 1 ,.,.) = \n",
       "    1.0026e-02  2.5861e-04 -3.5999e-03  ...   1.6859e-02  5.2949e-03  3.5296e-02\n",
       "  \n",
       "  ( 2 ,.,.) = \n",
       "    1.7713e-01 -1.7961e-01  1.0430e-01  ...   4.8649e-04 -2.1132e-01 -1.4650e-02\n",
       "  ... \n",
       "  \n",
       "  ( 7 ,.,.) = \n",
       "    1.0125e-01  7.5279e-02 -4.1263e-03  ...  -1.3016e-03 -1.9892e-02  3.0247e-02\n",
       "  \n",
       "  ( 8 ,.,.) = \n",
       "    5.5009e-02 -4.5345e-01 -5.2930e-03  ...   3.5153e-03 -3.5104e-02  6.1875e-03\n",
       "  \n",
       "  ( 9 ,.,.) = \n",
       "    4.6364e-03  7.6946e-03 -1.1887e-02  ...   2.8283e-01  1.0168e-02  1.5855e-02\n",
       "  [torch.FloatTensor of size 10x1x400]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.reset()\n",
    "test_model(V(T(np.expand_dims(trn_lm[0:10], -1))).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "    2\n",
       "  566\n",
       "   18\n",
       "   40\n",
       "   36\n",
       "    5\n",
       "  108\n",
       "    7\n",
       "  144\n",
       "  250\n",
       "[torch.LongTensor of size 10x1]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V(T(np.expand_dims(trn_lm[0:10], -1))).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
